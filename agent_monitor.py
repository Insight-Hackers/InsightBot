import pandas as pd
import re
from datetime import datetime
from functools import reduce
from tabulate import tabulate
import uuid
import psycopg2
from thefuzz import fuzz
from datetime import date
import time

import os

LAST_PROCESSED_FILE = "last_processed.txt"

SLACK_TO_GIT_USERNAME_MAP = {
    "efrat.wilinger@gmail.com": "EfratWilinger",
    "yafit3278@gmail.com": "YafitCohen3278",
    "aditoubin@gmail.com": "AdiToubin",
    "avitalhoyzer@gmail.com": "AvitalHoyzer",
    "meitav.bin@gmail.com": "meitav1",
    "eszilber29@gmail.com": "EtiZilberlicht",
    "ayala62005@gmail.com": "AyalaTrachtman",
    "y7697086@gmail.com": "yaelshneor2004"
}

def get_canonical_username(slack_email: str = None, git_username: str = None) -> str:
    if slack_email and slack_email in SLACK_TO_GIT_USERNAME_MAP:
        return SLACK_TO_GIT_USERNAME_MAP[slack_email]
    if git_username and git_username in SLACK_TO_GIT_USERNAME_MAP.values():
        return git_username
    return None

def add_canonical_user_column(df: pd.DataFrame, slack_col: str = "user_id", git_col: str = "author") -> pd.DataFrame:
    def map_user(row):
        return get_canonical_username(row.get(slack_col), row.get(git_col))
    df["canonical_username"] = df.apply(map_user, axis=1)
    return df

def load_filtered_github_commits():
    df = load_github_commits()
    last_ts = get_last_processed_time("github_commits_raw")
    if last_ts:
        # ×”×¤×•×š ××ª last_ts ×œÖ¾UTC ×× ×¦×¨×™×š
        if last_ts.tzinfo is None:
            last_ts = pd.Timestamp(last_ts).tz_localize("UTC")

        df['ts_dt'] = pd.to_datetime(df['timestamp'], utc=True)
        df = df[df['ts_dt'] > last_ts].copy()
        df = df.drop(columns=['ts_dt'])
        print(f"ğŸ§¹ ×¡×•× × ×• ×§×•××™×˜×™× ×œ×¤× ×™ {last_ts} - × ×•×ª×¨×• {len(df)}")
    return df


def load_filtered_github_issues():
    df = load_github_issues()
    last_ts = get_last_processed_time("github_issues_raw")
    if last_ts:
        if last_ts.tzinfo is None:
            last_ts = pd.Timestamp(last_ts)
            if last_ts.tzinfo is None:
                last_ts = last_ts.tz_localize("UTC")

        df['ts_dt'] = pd.to_datetime(df['created_at'], utc=True)
        df = df[df['ts_dt'] > last_ts].copy()
        df = df.drop(columns=['ts_dt'])
        print(f"ğŸ§¹ ×¡×•× × ×• Issues ×œ×¤× ×™ {last_ts} - × ×•×ª×¨×• {len(df)}")

    return df



def load_filtered_github_reviews():
    df = load_github_reviews()
    last_ts = get_last_processed_time("github_reviews_raw")
    if last_ts:
        if last_ts.tzinfo is None:
            last_ts = pd.Timestamp(last_ts)
            if last_ts.tzinfo is None:
                last_ts = last_ts.tz_localize("UTC")

        df['ts_dt'] = pd.to_datetime(df['created_at'], utc=True)
        df = df[df['ts_dt'] > last_ts].copy()
        df = df.drop(columns=['ts_dt'])
        print(f"ğŸ§¹ ×¡×•× × ×• Reviews ×œ×¤× ×™ {last_ts} - × ×•×ª×¨×• {len(df)}")
    return df


def load_filtered_github_prs():
    df = load_github_prs()
    last_ts = get_last_processed_time("github_prs_raw")
    if last_ts:
        import pandas as pd  # ×•×“× ×©×–×” ×§×™×™× ×‘×¨××© ×”×§×•×‘×¥

    if last_ts.tzinfo is None:
        last_ts = pd.Timestamp(last_ts).tz_localize("UTC")
    else:
        last_ts = pd.Timestamp(last_ts)

        df['ts_dt'] = pd.to_datetime(df['created_at'], utc=True)
        df = df[df['ts_dt'] > last_ts].copy()
        df = df.drop(columns=['ts_dt'])
        print(f"ğŸ§¹ ×¡×•× × ×• PRs ×œ×¤× ×™ {last_ts} - × ×•×ª×¨×• {len(df)}")
    return df


# --- ×¤×•× ×§×¦×™×•×ª ×—×™×‘×•×¨×™× ×œ×“××˜× ×‘×™×™×¡ ---


def update_last_processed_time(table_name, last_time):
    conn = get_db_connection()
    with conn.cursor() as cur:
        cur.execute("""
            INSERT INTO agent_progress (table_name, last_processed_at)
            VALUES (%s, %s)
            ON CONFLICT (table_name)
            DO UPDATE SET last_processed_at = EXCLUDED.last_processed_at
        """, (table_name, last_time))
        conn.commit()
    conn.close()


def get_last_processed_time(table_name):
    conn = get_db_connection()
    with conn.cursor() as cur:
        cur.execute(
            "SELECT last_processed_at FROM agent_progress WHERE table_name = %s", (table_name,))
        result = cur.fetchone()
    conn.close()
    return result[0] if result else None


def get_db_connection():
    """××§×™× ×—×™×‘×•×¨ ×œ××¡×“ ×”× ×ª×•× ×™× ×©×œ Supabase."""
    return psycopg2.connect(
        dbname="postgres",
        user="postgres.apphxbmngxlclxromyvt",
        password="insightbot2025",
        host="aws-0-eu-north-1.pooler.supabase.com",
        port="6543"
    )

# --- ×¤×•× ×§×¦×™×•×ª ×˜×¢×™× ×ª × ×ª×•× ×™× ×’×•×œ××™×™× ×-Supabase ---


def load_slack_messages():
    conn = get_db_connection()
    query = "SELECT * FROM slack_messages_raw"
    try:
        df = pd.read_sql(query, conn)
        if 'user' in df.columns and 'canonical_username' not in df.columns:
            df = df.rename(columns={'user': 'canonical_username'})
        df = normalize_user_ids(df)
        return df
    finally:
        conn.close()


def load_filtered_slack_messages():
    """×˜×•×¢×Ÿ ×”×•×“×¢×•×ª Slack ××¡×•× × ×•×ª ×œ×¤×™ ×ª××¨×™×š ××—×¨×•×Ÿ ×©×˜×•×¤×œ ××”×˜×‘×œ×” agent_progress."""
    df = load_slack_messages()
    last_ts = get_last_processed_time("slack_messages_raw")

    if last_ts:
        df['ts_dt'] = pd.to_datetime(df['ts'], unit='s', utc=True)
        last_ts = pd.Timestamp(last_ts)
        if last_ts.tzinfo is None:
            last_ts = last_ts.tz_localize("UTC")

            print(f"ğŸ§¹ ×¡×•× × ×• ×”×•×“×¢×•×ª ×œ×¤× ×™ {last_ts} - × ×•×ª×¨×• {len(df)}")
            df = df.drop(columns=['ts_dt'])

    # ×¡×™× ×•×Ÿ ×”×•×“×¢×•×ª ×©× ××—×§×•
    if 'deleted' in df.columns:
        before = len(df)
        df = df[df['deleted'] != True].copy()
        print(f"ğŸ—‘ ×¡×•× × ×• {before - len(df)} ×”×•×“×¢×•×ª ×©× ××—×§×•")
        replies_df = add_canonical_user_column(replies_df, slack_col="user_id")
        slack_reports_df = add_canonical_user_column(slack_reports_df, slack_col="user_id")
   
    return df




def load_slack_reports():
    conn = get_db_connection()
    query = "SELECT * FROM slack_reports_raw"
    try:
        df = pd.read_sql(query, conn)
        df = normalize_user_ids(df)
        if df.empty:
            return pd.DataFrame(columns=['id', 'canonical_username', 'text', 'ts', 'channel_id', 'report_type', 'status'])
        return df
    finally:
        conn.close()


def load_github_issues():
    """×˜×•×¢×Ÿ ×’×™×œ×™×•× ×•×ª (issues) ×-GitHub ××˜×‘×œ×ª github_issues_raw."""
    conn = get_db_connection()
    query = "SELECT * FROM github_issues_raw"
    try:
        df = pd.read_sql(query, conn)
        if df.empty:
            # ×”×’×“×¨ ×¢××•×“×•×ª ×¦×¤×•×™×•×ª ×¢×‘×•×¨ DataFrame ×¨×™×§
            return pd.DataFrame(columns=['id', 'canonical_username', 'title', 'body', 'state', 'created_at', 'closed_at', 'repository', 'url', 'is_critical'])
        return df
    finally:
        conn.close()


def load_github_commits():
    """×˜×•×¢×Ÿ ×§×•××™×˜×™× ×-GitHub ××˜×‘×œ×ª github_commits_raw."""
    conn = get_db_connection()
    query = "SELECT * FROM github_commits_raw"
    try:
        df = pd.read_sql(query, conn)
        if df.empty:
            # ×”×’×“×¨ ×¢××•×“×•×ª ×¦×¤×•×™×•×ª ×¢×‘×•×¨ DataFrame ×¨×™×§
            return pd.DataFrame(columns=['sha', 'author', 'message', 'timestamp', 'repository', 'url'])
        # ×•×“× ×©×¢××•×“×ª 'author' ××©×•× ×” ×œ-'user_id' ×× ×™×© ×¦×•×¨×š
        if 'author' in df.columns and 'canonical_username' not in df.columns:
            df = df.rename(columns={'author': 'canonical_username'})
        return df
    finally:
        conn.close()


def analyze_pull_requests(github_prs_df):
    if github_prs_df.empty:
        return pd.DataFrame(columns=['canonical_username', 'date', 'pull_requests'])
    github_prs_df['date'] = pd.to_datetime(github_prs_df['created_at']).dt.date
    return github_prs_df.groupby(['canonical_username', 'date']).size().reset_index(name='pull_requests')


def load_github_reviews():
    """×˜×•×¢×Ÿ ×‘×™×§×•×¨×•×ª (reviews) ×-GitHub ××˜×‘×œ×ª github_reviews_raw."""
    conn = get_db_connection()
    query = "SELECT * FROM github_reviews_raw"
    try:
        df = pd.read_sql(query, conn)
        if df.empty:
            # ×”×’×“×¨ ×¢××•×“×•×ª ×¦×¤×•×™×•×ª ×¢×‘×•×¨ DataFrame ×¨×™×§
            return pd.DataFrame(columns=['id', 'pull_request_id', 'canonical_username', 'state', 'body', 'created_at', 'url'])
        return df
    finally:
        conn.close()


def load_github_prs():
    """×˜×•×¢×Ÿ ×‘×§×©×•×ª ××©×™×›×” (pull requests) ×-GitHub ××˜×‘×œ×ª github_prs_raw."""
    conn = get_db_connection()
    query = "SELECT * FROM github_prs_raw"
    try:
        df = pd.read_sql(query, conn)
        if df.empty:
            # ×”×’×“×¨ ×¢××•×“×•×ª ×¦×¤×•×™×•×ª ×¢×‘×•×¨ DataFrame ×¨×™×§
            return pd.DataFrame(columns=['id', 'canonical_username', 'title', 'state', 'created_at', 'closed_at', 'merged_at', 'repository', 'url'])
        return df
    finally:
        conn.close()

# --- ×¤×•× ×§×¦×™×•×ª ×× ×œ×™×–×” ---


def analyze_total_messages(slack_df):
    """×× ×ª×— ××ª ×¡×š ×”×”×•×“×¢×•×ª ×©× ×©×œ×—×• ×¢×œ ×™×“×™ ×›×œ ××©×ª××© ×‘×™×•×."""
    slack_df['date'] = pd.to_datetime(slack_df['ts'], unit='s').dt.date
    return slack_df.groupby(['canonical_username', 'date']).size().reset_index(name='total_messages')


def normalize_user_ids(df):
    """×× ×™×© ×¢××•×“×ª user â€“ ×©× ×” ××ª ×©××” ×œÖ¾user_id"""
    if 'user' in df.columns and 'canonical_username' not in df.columns:
        df = df.rename(columns={'user': 'canonical_username'})
    return df


def analyze_help_requests(slack_df):
    """××–×”×” ×•×× ×ª×— ×‘×§×©×•×ª ×¢×–×¨×” ××”×•×“×¢×•×ª Slack, ×›×•×œ×œ ×–×™×”×•×™ ×©×’×™××•×ª ×›×ª×™×‘."""
    help_keywords = [
        "×¢×–×¨×”", "×‘×¢×™×”", "×©××œ×”", "×œ× ××¦×œ×™×—", "× ×ª×§×¢", "×ª×§×•×¢",
        "××™×–×” ×©×œ×‘", "××™×š ×××©×™×›×™×", "××” ×¢×•×©×™×", "××™×©×”×• ×™×›×•×œ ×œ×¢×–×•×¨",
        "×œ× ×¢×•×‘×“", "××©×”×• ×œ× ×ª×§×™×Ÿ", "×¦×¨×™×š ×¢×–×¨×”", "××™×š ×××©×™×›×™×",
        "××™×š ××ª×§×“×", "××” ×”×©×œ×‘ ×”×‘×", "××” ×œ×¢×©×•×ª", "××” ×”×‘×¢×™×”",
        "help", "stuck", "issue", "problem", "need help", "can't", "error",
        "ğŸ†˜", "â“", "ğŸ™‹â€â™€"
    ]

    # ×©×œ×‘ ×¨××©×•×Ÿ: × ×–×”×” ×”×•×“×¢×•×ª ×©××›×™×œ×•×ª ×‘×™×˜×•×™ ×¨×’×™×œ
    regex_pattern = '|'.join(map(re.escape, help_keywords))
    basic_matches = slack_df['text'].str.contains(
        regex_pattern, case=False, na=False)

    # ×©×œ×‘ ×©× ×™: × ×–×”×” ×”×•×“×¢×•×ª ×¢× ×©×’×™××•×ª ×›×ª×™×‘ â€“ ×œ×¤×™ fuzzy match
    def fuzzy_contains_help(text):
        if not isinstance(text, str):
            return False
        words = text.split()
        for word in words:
            for keyword in help_keywords:
                if fuzz.partial_ratio(word.lower(), keyword.lower()) >= 85:
                    return True
        return False

    fuzzy_matches = slack_df['text'].apply(fuzzy_contains_help)

    # ×©×™×œ×•×‘ ×©× ×™ ×”××¡×œ×•×œ×™×
    help_msgs = slack_df[basic_matches | fuzzy_matches].copy()
    help_msgs['type'] = 'help_request'
    help_msgs['date'] = pd.to_datetime(help_msgs['ts'], unit='s').dt.date

    return help_msgs


def analyze_help_requests_count(slack_df):
    """×¡×•×¤×¨ ××ª ××¡×¤×¨ ×‘×§×©×•×ª ×”×¢×–×¨×” ×œ×›×œ ××©×ª××© ×‘×™×•×."""
    help_df = analyze_help_requests(slack_df)
    return help_df.groupby(['canonical_username', 'date']).size().reset_index(name='help_requests')


def analyze_message_replies(messages_df, replies_df, slack_reports_df, github_issues_df):
    """×× ×ª×— ×ª×’×•×‘×•×ª ×œ×”×•×“×¢×•×ª ×•×× ×¡×” ×œ×§×‘×•×¢ ×¡×˜×˜×•×¡ ×¤×ª×¨×•×Ÿ."""
    if 'parent_id' in replies_df.columns and not replies_df.empty:
        replies_count = replies_df.groupby(
            'parent_id').size().reset_index(name='num_replies')
    else:
        replies_count = pd.DataFrame(columns=['parent_id', 'num_replies'])

    messages = messages_df.merge(
        replies_count, how='left', left_on='id', right_on='parent_id')
    messages['num_replies'] = messages['num_replies'].fillna(0)

    def is_resolved(row):
        text = str(row['text']).lower()  # ×•×“× ×©×–×” ××—×¨×•×–×ª
        resolved_keywords = ['×ª×•×“×”', '×”×¡×ª×“×¨×ª×™', '× ×¤×ª×¨', 'works']
        if any(k in text for k in resolved_keywords):
            return True

        # ×‘×“×™×§×” ××•×œ slack_reports_df
        # ×•×“× ×©-slack_reports_df ×œ× ×¨×™×§ ×•×©×™×© ×‘×• ××ª ×”×¢××•×“×•×ª ×”× ×“×¨×©×•×ª
        if not slack_reports_df.empty and all(col in slack_reports_df.columns for col in ['canonical_username', 'ts', 'text']):
            user_reports = slack_reports_df[
                (slack_reports_df['canonical_username'] == row['canonical_username']) &
                (pd.to_datetime(
                    slack_reports_df['ts'], unit='s').dt.date == row['date'])
            ]
            if not user_reports.empty and any(k in user_reports['text'].str.lower().str.cat(sep=' ') for k in ['×”×‘×¢×™×” × ×¤×ª×¨×”', '×˜×•×¤×œ', '× ×¤×ª×¨×”']):
                return True

        # ×‘×“×™×§×” ××•×œ github_issues_df
        # ×•×“× ×©-github_issues_df ×œ× ×¨×™×§ ×•×©×™×© ×‘×• ××ª ×”×¢××•×“×•×ª ×”× ×“×¨×©×•×ª
        if not github_issues_df.empty and all(col in github_issues_df.columns for col in ['canonical_username', 'created_at', 'closed_at', 'state']):
            issue_matches = github_issues_df[
                (github_issues_df['canonical_username'] == row['canonical_username']) &
                (pd.to_datetime(github_issues_df['created_at']).dt.date <= row['date']) &
                ((pd.to_datetime(github_issues_df['closed_at'], errors='coerce').dt.date == row['date']) |
                 (github_issues_df['state'] == 'closed'))
            ]
            if not issue_matches.empty:
                return True
        return False

    def classify(row):
        if row['num_replies'] == 0:
            return 'open'
        elif is_resolved(row):
            return 'resolved'
        return 'needs_attention'

    # ×•×“× ×©-messages_df ××›×™×œ ××ª ×”×¢××•×“×•×ª ×”× ×“×¨×©×•×ª ×œ×¤× ×™ ×”-apply
    if not messages_df.empty and 'text' in messages_df.columns and 'canonical_username' in messages_df.columns and 'date' in messages_df.columns:
        messages['status'] = messages.apply(classify, axis=1)
    else:
        # ×× messages_df ×¨×™×§ ××• ×—×¡×¨×•×ª ×¢××•×“×•×ª, ×¦×•×¨ ×¢××•×“×ª 'status' ×¨×™×§×”
        messages['status'] = None  # ××• 'unknown' ××• ×¢×¨×š ××—×¨ ×©××ª××™× ×œ×›×

    messages['date'] = pd.to_datetime(messages['ts'], unit='s').dt.date
    return messages[['id', 'canonical_username', 'text', 'num_replies', 'status', 'date']]


def analyze_stuck_status(slack_df, replies_df, slack_reports_df, github_issues_df):
    """×× ×ª×— ××ª ×¡×˜×˜×•×¡ ×”××©×ª××©×™× ('×ª×§×•×¢×™×', '×¤×¢×™×œ×™×', '× ×¤×ª×¨×•')."""
    help_df = analyze_help_requests(slack_df)
    replies_analysis = analyze_message_replies(
        help_df, replies_df, slack_reports_df, github_issues_df)

    # ×•×“× ×©-replies_analysis ××›×™×œ ××ª ×”×¢××•×“×•×ª ×”× ×“×¨×©×•×ª
    if replies_analysis.empty or not all(col in replies_analysis.columns for col in ['id', 'status']):
        return pd.DataFrame(columns=['canonical_username', 'date', 'stuck_passive', 'stuck_active', 'resolved'])

    merged = help_df[['id', 'canonical_username', 'date']].merge(
        replies_analysis[['id', 'status']], on='id')

    # ×•×“× ×©-merged ×œ× ×¨×™×§ ×œ×¤× ×™ pivot_table
    if merged.empty:
        return pd.DataFrame(columns=['canonical_username', 'date', 'stuck_passive', 'stuck_active', 'resolved'])

    summary = merged.pivot_table(
        index=['canonical_username', 'date'], columns='status', aggfunc='size', fill_value=0).reset_index()
    return summary.rename(columns={
        'open': 'stuck_passive',
        'needs_attention': 'stuck_active',
        'resolved': 'resolved'
    })


def analyze_completed_tasks(github_issues_df):
    """×× ×ª×— ××©×™××•×ª GitHub ×©×”×•×©×œ××•."""
    if github_issues_df.empty:
        return pd.DataFrame(columns=['canonical_username', 'date', 'completed_tasks'])

    github_issues_df['date'] = pd.to_datetime(
        github_issues_df['closed_at'], errors='coerce').dt.date
    filtered = github_issues_df[(
        github_issues_df['state'] == 'closed') & github_issues_df['date'].notna()]
    return filtered.groupby(['canonical_username', 'date']).size().reset_index(name='completed_tasks')


def analyze_open_tasks(github_issues_df):
    """×× ×ª×— ××©×™××•×ª GitHub ×¤×ª×•×—×•×ª."""
    if github_issues_df.empty:
        return pd.DataFrame(columns=['canonical_username', 'date', 'open_tasks'])

    github_issues_df['date'] = pd.to_datetime(
        github_issues_df['created_at']).dt.date
    open_issues = github_issues_df[github_issues_df['state'] == 'open']
    return open_issues.groupby(['canonical_username', 'date']).size().reset_index(name='open_tasks')


def analyze_commits(github_commits_df):
    """×× ×ª×— ×§×•××™×˜×™× ×©×œ GitHub."""
    if github_commits_df.empty:
        return pd.DataFrame(columns=['canonical_username', 'date', 'commits'])

    github_commits_df['date'] = pd.to_datetime(
        github_commits_df['timestamp']).dt.date
    # ×•×“× ×©×”×¢××•×“×” 'author' ×§×™×™××ª ×œ×¤× ×™ ×”-groupby
    if 'author' not in github_commits_df.columns:
        # ×× 'author' ×œ× ×§×™×™××ª, ×›×‘×¨ ×©×™× ×™×ª ××•×ª×” ×œ-user_id ×‘-load_github_commits, ××• ×©×”×™× ×¤×©×•×˜ ×—×¡×¨×”
        # ×‘××§×¨×” ×›×–×” × ×—×–×™×¨ DataFrame ×¨×™×§ ×¢× ×”×¢××•×“×•×ª ×”×¦×¤×•×™×•×ª
        return pd.DataFrame(columns=['canonical_username', 'date', 'commits'])

    return github_commits_df.groupby(['author', 'date']).size().reset_index(name='commits').rename(columns={'author': 'canonical_username'})


def analyze_reviews(github_reviews_df):
    """×× ×ª×— ×‘×™×§×•×¨×•×ª ×§×•×“ ×©×œ GitHub."""
    if github_reviews_df.empty:
        return pd.DataFrame(columns=['canonical_username', 'date', 'reviews'])

    github_reviews_df['date'] = pd.to_datetime(
        github_reviews_df['created_at']).dt.date
    return github_reviews_df.groupby(['canonical_username', 'date']).size().reset_index(name='reviews')

# --- ××™×–×•×’ ×ª×•×¦××•×ª ×”× ×™×ª×•×— ×œ×˜×‘×œ×” ××—×ª (user_daily_summary) ---


def build_user_daily_summary(slack_df, replies_df, slack_reports_df,
                             github_commits_df, github_reviews_df,
                             github_issues_df, github_prs_df):
    """×‘× ××™ ×¡×™×›×•× ×™×•××™ ×¢×‘×•×¨ ×›×œ ××©×ª××© ×¢×œ ×‘×¡×™×¡ ×›×œ ×”× ×ª×•× ×™× ×”×× ×•×ª×—×™×, ×›×•×œ×œ PR × ×¤×¨×“."""
    dfs = [
        analyze_total_messages(slack_df),
        analyze_help_requests_count(slack_df),
        analyze_stuck_status(slack_df, replies_df,
                             slack_reports_df, github_issues_df),
        analyze_completed_tasks(github_issues_df),
        analyze_open_tasks(github_issues_df),
        analyze_commits(github_commits_df),
        analyze_reviews(github_reviews_df),
        analyze_pull_requests(github_prs_df)  # âœ… × ×•×¡×¤×” ×”×¢××•×“×” pull_requests
    ]

    # ××™×–×•×’ ×›×œ ×”×˜×‘×œ××•×ª ×œ×¤×™ user_id + date
    user_summary_df = reduce(
        lambda left, right: pd.merge(
            left, right, on=['canonical_username', 'date'], how='outer'),
        dfs
    ).fillna(0)

    # ×”××¨×ª ×¢××•×“×•×ª ××¡×¤×¨×™×•×ª ×œÖ¾int
    for col in user_summary_df.columns:
        if col not in ['canonical_username', 'date']:
            user_summary_df[col] = user_summary_df[col].astype(int)

    # ×©×™× ×•×™ ×©× 'date' ×œÖ¾'day'
    user_summary_df = user_summary_df.rename(columns={'date': 'day'})

    return user_summary_df


# --- ×™×¦×™×¨×ª ×˜×‘×œ×ª project_status_daily ---


def build_project_status_daily(github_prs_df, github_issues_df, all_users_df):
    """×‘× ××™ ×¡×™×›×•× ×™×•××™ ×œ×¡×˜×˜×•×¡ ×”×¤×¨×•×™×§×˜."""
    # ×˜×™×¤×•×œ ×‘-DataFrame ×¨×™×§ ×©×œ PRs
    if github_prs_df.empty:
        return pd.DataFrame([{
            'day': datetime.now().date(),  # ×ª××¨×™×š × ×•×›×—×™
            'open_prs': 0,
            'stale_prs': 0,
            'closed_prs': 0,
            'critical_issues': 0,
            'active_contributors': 0
        }])

    prs_df = github_prs_df.copy()
    prs_df['day'] = pd.to_datetime(prs_df['created_at']).dt.date
    prs_df['closed_day'] = pd.to_datetime(
        prs_df['closed_at'], errors='coerce').dt.date

    today = prs_df['day'].max()  # ×§×‘×œ×ª ×”×ª××¨×™×š ×”××§×¡×™××œ×™ ×× ×ª×•× ×™ ×”-PRs ×”×§×™×™××™×
    if pd.isna(today):  # ×× ××™×Ÿ PRs ×‘×›×œ×œ, today ×™×”×™×” NaT
        today = pd.Timestamp.utcnow().date()

    stale_threshold = pd.Timestamp(today, tz="UTC") - pd.Timedelta(days=3)
    stale_prs = prs_df[(prs_df['state'] == 'open') & (
        pd.to_datetime(prs_df['created_at']) < stale_threshold)]

    open_prs_count = prs_df[(prs_df['state'] == 'open')
                            & (prs_df['day'] == today)].shape[0]
    closed_prs_count = prs_df[(prs_df['state'] == 'closed') & (
        prs_df['closed_day'] == today)].shape[0]
    stale_prs_count = stale_prs.shape[0]

    critical_issues_count = 0
    # ×•×“× ×©-github_issues_df ×œ× ×¨×™×§ ×•×©×™×© ×‘×• ××ª ×”×¢××•×“×•×ª ×”× ×“×¨×©×•×ª
    if not github_issues_df.empty and all(col in github_issues_df.columns for col in ['is_critical', 'state', 'created_at']):
        critical_issues_count = github_issues_df[
            # is_critical ×™×›×•×œ ×œ×”×™×•×ª ×¢××•×“×” ×©×—×¡×¨×”
            (github_issues_df.get('is_critical', False)) &
            (github_issues_df['state'] == 'open') &
            (pd.to_datetime(github_issues_df['created_at']).dt.date == today)
        ].shape[0]

    active_users = 0
    # ×•×“× ×©-all_users_df ×œ× ×¨×™×§ ×•×©×™×© ×‘×• ××ª ×”×¢××•×“×•×ª ×”× ×“×¨×©×•×ª
    if not all_users_df.empty and all(col in all_users_df.columns for col in ['day', 'canonical_username']):
        active_users = all_users_df[all_users_df['day']
                                    == today]['canonical_username'].nunique()

    return pd.DataFrame([{
        'day': today,
        'open_prs': open_prs_count,
        'stale_prs': stale_prs_count,
        'closed_prs': closed_prs_count,
        'critical_issues': critical_issues_count,
        'active_contributors': active_users
    }])

# --- ×™×¦×™×¨×ª ×˜×‘×œ×ª alerts ---


def build_alerts(user_summary_df):
    """×‘× ××™ ×”×ª×¨××•×ª ×¢×œ ×‘×¡×™×¡ ×¡×™×›×•× ×”××©×ª××©×™× ×”×™×•××™."""
    alerts = []
    # ×•×“× ×©-user_summary_df ×œ× ×¨×™×§ ×•×©×™×© ×‘×• ××ª ×”×¢××•×“×•×ª ×”× ×“×¨×©×•×ª
    if user_summary_df.empty:
        return pd.DataFrame(columns=['id', 'canonical_username', 'type', 'message', 'severity', 'created_at'])

    for _, row in user_summary_df.iterrows():
        # ×‘×“×™×§×•×ª ×¢× .get() ×›×“×™ ×œ×× ×•×¢ KeyError ×× ×¢××•×“×” ×—×¡×¨×” ×××™×–×•×©×”×™ ×¡×™×‘×”
        if row.get('stuck_passive', 0) > 0:
            alerts.append({
                'id': str(uuid.uuid4()),
                'user_id': row['canonical_username'],
                'type': 'stuck_passive',
                'message': f"{row['canonical_username']} ×œ× ×”×ª×§×“× ×‘××©×™××” ×‘××©×š ×–××Ÿ ××”.",
                'severity': 'medium',
                'created_at': row['day']
            })
        if row.get('help_requests', 0) > 0 and row.get('resolved', 0) == 0:
            alerts.append({
                'id': str(uuid.uuid4()),
                'user_id': row['canonical_username'],
                'type': 'unanswered_help',
                'message': f"{row['canonical_username']} ×‘×™×§×© ×¢×–×¨×” ××š ×œ× ×§×™×‘×œ ××¢× ×”.",
                'severity': 'high',
                'created_at': row['day']
            })
        # ×× ×›×œ×œ ×”×¢××•×“×•×ª ×”×œ×œ×• ×”×Ÿ 0, ××– ×™×© ×—×•×¡×¨ ×¤×¢×™×œ×•×ª
        # ×”×•×¡×¤×ª×™ ×’× ××©×™××•×ª
        if all(row.get(col, 0) == 0 for col in ['total_messages', 'commits', 'reviews', 'completed_tasks', 'open_tasks']):
            alerts.append({
                'id': str(uuid.uuid4()),
                'user_id': row['canonical_username'],
                'type': 'inactivity',
                'message': f"{row['canonical_username']} ×œ× ×”×™×” ×¤×¢×™×œ ×›×œ×œ ×‘×™×•× {row['day']}.",
                'severity': 'low',
                'created_at': row['day']
            })

    return pd.DataFrame(alerts)

# --- ×¤×•× ×§×¦×™×™×ª ×©××™×¨×” ×œ××¡×“ ×”× ×ª×•× ×™× ---


def save_dataframe_to_db(df, table_name, conflict_columns=None):
    """×©×•××¨ DataFrame ×œ×˜×‘×œ×” ×‘××¡×“ ×”× ×ª×•× ×™× ×©×œ Supabase, ×›×•×œ×œ ×¢×“×›×•×Ÿ ×‘××§×¨×” ×©×œ CONFLICT."""
    if df.empty:
        print(f"âš  ×”×˜×‘×œ×” {table_name} ×¨×™×§×” - ×œ× × ×©××¨ ×›×œ×•×")
        return

    conn = get_db_connection()
    cursor = conn.cursor()

    try:
        # ×”××¨×ª ×¡×•×’×™ × ×ª×•× ×™×
        for column in df.columns:
            if pd.api.types.is_datetime64_any_dtype(df[column]):
                df[column] = df[column].dt.to_pydatetime()
            elif pd.api.types.is_object_dtype(df[column]):
                df[column] = df[column].astype(str)

        for _, row in df.iterrows():
            cols = ','.join(df.columns)
            placeholders = ','.join(['%s'] * len(df.columns))
            values = tuple(row)

            if conflict_columns:
                conflict_clause = ', '.join(conflict_columns)
                update_clause = ', '.join([
                    f"{col} = EXCLUDED.{col}"
                    for col in df.columns if col not in conflict_columns
                ])
                sql = f"""
                INSERT INTO {table_name} ({cols})
                VALUES ({placeholders})
                ON CONFLICT ({conflict_clause}) DO UPDATE SET {update_clause}
                """
            else:
                sql = f"""
                INSERT INTO {table_name} ({cols})
                VALUES ({placeholders})
                ON CONFLICT DO NOTHING
                """

            cursor.execute(sql, values)

        conn.commit()
        print(f"âœ… × ×©××¨×• {len(df)} ×©×•×¨×•×ª ×œ×˜×‘×œ×” {table_name}")

    except Exception as e:
        print(f"âŒ ×©×’×™××” ×‘×©××™×¨×” ×œ×˜×‘×œ×” {table_name}: {e}")
        conn.rollback()
    finally:
        cursor.close()
        conn.close()


#def load_github_commits():
    #conn = get_db_connection()
    #df = pd.read_sql("SELECT * FROM github_commits_raw", conn)
    #conn.close()
    #return df


# ============================
# ğŸ§ª MAIN DEMO - ×”×¨×¦×ª ×“××• ××œ××”
# ============================


def agent_monitor():
    print("ğŸš€ ××ª×—×™×œ ×œ× ×ª×— × ×ª×•× ×™× ×Ö¾Supabase...")
    time.sleep(10)
    try:

        # --- 1. ×˜×¢×™× ×ª ×›×œ ×”-DataFrames ×”× ×“×¨×©×™× ×××¡×“ ×”× ×ª×•× ×™× ---
        from slack_deletion_sync import load_filtered_slack_messages
        slack_df = load_filtered_slack_messages()

        print(f"ğŸ“Š × ×˜×¢× ×• {len(slack_df)} ×”×•×“×¢×•×ª ×-Slack")

        if slack_df.empty:
            print("âš  ×œ× × ××¦××• ×”×•×“×¢×•×ª ×‘-Slack - ××¡×™×™×")
            return

        # replies_df ××‘×•×¡×¡ ×¢×œ slack_df
        replies_df = slack_df[slack_df['parent_id'].notna()].copy()

        # ×˜×•×¢×Ÿ ×“×•×—×•×ª ×¡×œ××§, ×™×—×–×™×¨ DF ×¢× ×¢××•×“×•×ª ×’× ×× ×”×˜×‘×œ×” ×¨×™×§×”
        slack_reports_df = load_slack_reports()

        # ×˜×•×¢×Ÿ × ×ª×•× ×™ GitHub
        github_commits_df = load_filtered_github_commits()
        github_reviews_df = load_filtered_github_reviews()
        github_issues_df = load_filtered_github_issues()
        github_prs_df = load_filtered_github_prs()
        print(f"ğŸ“Š × ×˜×¢× ×• {len(github_issues_df)} ×’×™×œ×™×•× ×•×ª ×-GitHub")
        print(f"ğŸ“Š × ×˜×¢× ×• {len(github_commits_df)} ×§×•××™×˜×™× ×-GitHub")
        print(f"ğŸ“Š × ×˜×¢× ×• {len(github_reviews_df)} ×‘×™×§×•×¨×•×ª ×-GitHub")
        print(f"ğŸ“Š × ×˜×¢× ×• {len(github_prs_df)} ×‘×§×©×•×ª ××©×™×›×” ×-GitHub")
        github_commits_df = add_canonical_user_column(github_commits_df, git_col="author")
        github_reviews_df = add_canonical_user_column(github_reviews_df, git_col="user_id")
        github_issues_df = add_canonical_user_column(github_issues_df, git_col="user_id")
        github_prs_df = add_canonical_user_column(github_prs_df, git_col="user_id")
        slack_df = add_canonical_user_column(slack_df, slack_col="user_id")
        replies_df = add_canonical_user_column(replies_df, slack_col="user_id")
        slack_reports_df = add_canonical_user_column(slack_reports_df, slack_col="user_id")

        # --- 2. ×‘×™×¦×•×¢ ×”× ×™×ª×•×— ---
        print("ğŸ” ××‘×¦×¢ × ×™×ª×•×— × ×ª×•× ×™×...")
        user_summary_df = build_user_daily_summary(
            slack_df,
            replies_df,
            slack_reports_df,
            github_commits_df,
            github_reviews_df,
            github_issues_df,
            github_prs_df
        )
        # ×©××™×¨×” ×œ×¤×™ ×ª××¨×™×š ××§×¡×™××œ×™ ×¢×‘×•×¨ ×›×œ ×˜×‘×œ×”

        if not github_commits_df.empty:
            latest_commits = pd.to_datetime(
                github_commits_df['timestamp']).max()
            update_last_processed_time("github_commits_raw", latest_commits)

        if not github_reviews_df.empty:
            latest_reviews = pd.to_datetime(
                github_reviews_df['created_at']).max()
            update_last_processed_time("github_reviews_raw", latest_reviews)

        if not github_issues_df.empty:
            latest_issues = pd.to_datetime(
                github_issues_df['created_at']).max()
            update_last_processed_time("github_issues_raw", latest_issues)

        if not github_prs_df.empty:
            latest_prs = pd.to_datetime(github_prs_df['created_at']).max()
            update_last_processed_time("github_prs_raw", latest_prs)

        # --- 3. ×¢×“×›×•×Ÿ ×ª××¨×™×š ××—×¨×•×Ÿ ×©×˜×•×¤×œ (×œ×¤× ×™ ×©××™×¨×”) ---
        if not user_summary_df.empty:
            latest_date = user_summary_df['day'].max()
            if not user_summary_df.empty:
                latest_ts = slack_df['ts'].max()
            latest_dt = datetime.fromtimestamp(float(latest_ts))
            update_last_processed_time("slack_messages_raw", latest_dt)
            print(
                f"ğŸ•“ ×¢×•×“×›×Ÿ ×”×ª××¨×™×š ×”××—×¨×•×Ÿ ×©×˜×•×¤×œ ×‘×˜×‘×œ×” agent_progress: {latest_dt}")

            print(f"ğŸ•“ × ×©××¨ ×ª××¨×™×š ××—×¨×•×Ÿ ×©×˜×•×¤×œ: {latest_date}")

        project_status_daily_df = build_project_status_daily(
            github_prs_df, github_issues_df, user_summary_df
        )

        alerts_df = build_alerts(user_summary_df)

        # --- 3. ×”×“×¤×¡×ª ×ª×•×¦××•×ª ---
        print("\nğŸ“ˆ ×¡×™×›×•× ××©×ª××©×™× ×™×•××™:")
        print(tabulate(user_summary_df.head(), headers='keys', tablefmt='grid'))

        print("\nğŸ“Š ×¡×™×›×•× ×¡×˜×˜×•×¡ ×¤×¨×•×™×§×˜ ×™×•××™:")
        print(tabulate(project_status_daily_df.head(),
              headers='keys', tablefmt='grid'))

        print(f"\nğŸš¨ × ××¦××• {len(alerts_df)} ×”×ª×¨××•×ª")

        # --- 4. ×©××™×¨×” ×œ××¡×“ ×”× ×ª×•× ×™× ---
        print("\nğŸ’¾ ×©×•××¨ × ×ª×•× ×™× ×œ××¡×“ ×”× ×ª×•× ×™×...")

# âœ… ×”×•×¡×¤×ª ×‘×“×™×§×•×ª ×œ×¤× ×™ ×©××™×¨×”:
        print("âœ… ×˜×™×¤×•×¡×™×:")
        print(user_summary_df.dtypes)

        print("ğŸ” ×“×•×’××” ×œ×©×•×¨×”:")
        print(user_summary_df.head(1).to_dict())

        assert user_summary_df['day'].apply(
            lambda d: isinstance(d, date)).all(), "âŒ ×˜×™×¤×•×¡ ×©×’×•×™ ×‘-day"
        assert user_summary_df['canonical_username'].notna().all(), "âŒ user_id ×—×¡×¨"

# ×”××©×š ×©××™×¨×”
        save_dataframe_to_db(
            user_summary_df, 'user_daily_summary', conflict_columns=['canonical_username', 'day'])

        save_dataframe_to_db(project_status_daily_df, 'project_status_daily')
        save_dataframe_to_db(alerts_df, 'alerts')

        print("âœ… ×”× ×ª×•× ×™× × ×•×ª×—×• ×•× ×©××¨×• ×œ×˜×‘×œ××•×ª Supabase ×‘×”×¦×œ×—×”")

    except Exception as e:
        print(f"âŒ ×©×’×™××” ×›×œ×œ×™×ª: {e}")
        import traceback
        traceback.print_exc()


# ×× ××¨×™×¦×™× ××ª ×”×§×•×‘×¥ ×™×©×™×¨×•×ª, ×”×¤×¢×œ ××ª ×”×¤×•× ×§×¦×™×”
if __name__ == "__main__":
    agent_monitor()
